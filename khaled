import pandas as pd
startups = pd.read_csv("/content/drive/MyDrive/50_Startups.csv")
startups.head()

**Take a quick look at The data**

startups.head()

startups.info()

startups.isnull().mean() * 100

startups.describe()

startups["State"].value_counts()

import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
import plotly.express as px

px.scatter(startups, x="R&D Spend", y="Marketing Spend", color="Profit",  title="Startups Profit", width=800, height=600)

startups.hist(bins=50, figsize=(20,15));

**Create a Test Set**

from sklearn.model_selection import train_test_split

train_set, test_set = train_test_split(startups, test_size=0.2, random_state=42)

train_set.shape, test_set.shape

train_set.hist(bins=50,figsize=(20,15));

train_set.Profit.describe(),test_set.Profit.describe()

px.scatter(train_set, x="R&D Spend", y="Marketing Spend", color="Profit",  title="Startups Profit", width=800, height=600)

**EDA**

copy=startups.drop("State", axis='columns')

copy.quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 1])

copy.corr()

copy.corr()["Profit"].sort_values(ascending=False)

sns.pairplot(train_set);

px.scatter(train_set, x="R&D Spend" , y="Profit"  ,title="Startups Profit" , width=800 , height=600)

**The most promising attribute to predict the profit is the R&D Spend**

**Feature Engineering**

# Totalspending per profit
train_set["Total_spending_per_profit"] = (train_set["R&D Spend"]+train_set["Marketing Spend"])

copy=train_set.drop('State',axis=1)

copy.corr()["Profit"].sort_values(ascending=False)

R&D Spend is more informative than Total_spending_per_profit or Marketing Spend.

Total_spending_per_profit is more informative than Administration  and marketing spend.

**Data Cleaning**

**Prepare the Data for Machine Learning Algorithms**

# Split the data into features and labels

train_features = train_set.drop("Profit", axis=1)
train_labels = train_set["Profit"].copy()

# Impute missing values with median using SimpleImputer

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="median")

# Remove the text attribute because median can only be calculated on numerical attributes
startups_num = train_features.drop("State", axis=1)

# Fit the imputer instance to the training data using the fit() method
imputer.fit(startups_num)

# The imputer has simply computed the median of each attribute and stored the result in its statistics_ instance variable
imputer.statistics_

**Transformation Pipelines**

# Final Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
num_pipeline = Pipeline([   ('imputer', SimpleImputer(strategy="median")),
                            ('std_scaler', StandardScaler()),
                        ])

num_attribs = list(startups_num)
cat_attribs = ["State"]

full_pipeline = ColumnTransformer([ ("num", num_pipeline, num_attribs),
                                    ("cat", OneHotEncoder(drop = 'first'), cat_attribs),
                                  ])

train_features_prepared = full_pipeline.fit_transform(train_features)

**Linear Regression**

train_features_prepared

Total_spending_per_profit = train_features_prepared[:,5]
Total_spending_per_profit

Profit= train_labels.values
Profit

# Linear Regression

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(train_features_prepared, train_labels)

# Predictions
lin_reg_predictions = lin_reg.predict(train_features_prepared)


**Decision Tree**

# Decision Tree Regressor
from sklearn.tree import DecisionTreeRegressor
tree = DecisionTreeRegressor()
tree.fit(train_features_prepared, train_labels)

# Predictions
tree_predictions = tree.predict(train_features_prepared)

# Training Accuracy
from sklearn.metrics import r2_score
print("Linear Regression Accuracy: ", r2_score(train_labels, lin_reg_predictions))
print("Decision Tree Accuracy: ", r2_score(train_labels, tree_predictions))

**Cross Validation**

# Cross Validation for Linear Regression

from sklearn.model_selection import cross_val_score
lin_reg_scores = cross_val_score(lin_reg, train_features_prepared, train_labels, scoring="r2", cv=10)

print("Linear Regression Accuracy: ", lin_reg_scores)
print("Linear Regression Accuracy: ", round(lin_reg_scores.mean(),2))
print("Linear Regression Standard Deviation: ", round(lin_reg_scores.std(),2))

# Cross Validation for Decision Tree
from sklearn.model_selection import cross_val_score
tree_scores = cross_val_score(tree, train_features_prepared, train_labels, scoring="r2", cv=10)

print("Scores:", tree_scores)
print("Mean:", round(tree_scores.mean(),2))
print("Standard deviation:", round(tree_scores.std(),2))

**Fine-Tune Your Model**

# Find the best model using GridSearchCV
from sklearn.model_selection import GridSearchCV

param_grid = {'max_depth': [2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15,16,17,18] , 'max_features': [2, 4, 6, 8,10,12,13,14,15,16,17,18]}
grid_search = GridSearchCV(tree, param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(train_features_prepared, train_labels)
grid_search.best_params_

# Cross Validation for Decision Tree
tree_best = DecisionTreeRegressor(** grid_search.best_params_)
tree_best.fit(train_features_prepared, train_labels)

# Predictions
tree_bestpredictions = tree_best.predict(train_features_prepared)

# Testing Accuracy
test_features = test_set.drop("Profit", axis=1)
test_features["Total_spending_per_profit"] = test_features["R&D Spend"]+test_features["Marketing Spend"]
test_labels = test_set["Profit"].copy()

test_features_prepared = full_pipeline.transform(test_features)

lin_reg_predictions_test = lin_reg.predict(test_features_prepared)
tree_predictions_test = tree.predict(test_features_prepared)

print("Linear Regression Accuracy on Test Data: ", r2_score(test_labels, lin_reg_predictions_test))
print("Decision Tree Accuracy on Test Data: ", r2_score(test_labels,tree_predictions_test))

# Linear Regression vs. Decision Tree Training and Testing Accuracy
pd.DataFrame({ "Linear Regression": [r2_score(train_labels, lin_reg_predictions), r2_score(test_labels, lin_reg_predictions_test)],
                "Decision Tree": [r2_score(train_labels, tree_predictions), r2_score(test_labels, tree_predictions_test)]},
                index=["Training Accuracy", "Testing Accuracy"])

**Save Your Model**

# save linear regression model
import joblib
joblib.dump(lin_reg, "lin_reg.pkl")

# Load the model
lin_reg = joblib.load("lin_reg.pkl")

# Use the model to make predictions
lin_reg_predictions_test = lin_reg.predict(test_features_prepared)

# Save Pipeline
import joblib
joblib.dump(full_pipeline, "full_pipeline.pkl")

**Web App**

%%writefile app.py

import streamlit as st
import joblib
import numpy as np
import pandas as pd

# Load the model
lin_reg = joblib.load("lin_reg.pkl")

# Load the pipeline
full_pipeline = joblib.load("full_pipeline.pkl")

# Load the data
startups = pd.read_csv("/content/drive/MyDrive/50_Startups.csv")

# Create a title and sub-title
st.title("50startupprofitprediction")

st.write("""
This app predicts the **50startupprofitprediction**!
""")

# Take the input from the user
R&D Spend = st.slider('R&D Spend', float(startups['R&D Spend'].min()), float(startups['R&D Spend'].max()))
Administration = st.slider('Administration', float(startups['Administration'].min()), float(startups['Administration'].max()))
Marketing Spend	 = st.slider('Marketing Spend', float(startups['Marketing Spend'].min()), float(startups['Marketing Spend'].max()))
Profit = st.slider('Profit', float(startups['Profit'].min()), float(startups['Profit'].max()))
State = st.selectbox('California', 'Florida', 'New York')

# Store a dictionary into a variable
user_data = {'R&D Spend': R&D Spend,
'Administration': Administration ,
'Marketing Spend': Marketing Spend,
'State': State ,
'Profit': Profit,}

# Transform the data into a data frame
features = pd.DataFrame(user_data, index=[0])

# Additional transformations
features["Total_spending_per_profit"]= features["R&D Spend"]/features["Marketing Spend"]

# Pipeline
features_prepared = full_pipeline.transform(features)

# Predict the output
prediction = lin_reg.predict(features_prepared)[0]

# Set a subheader and display the prediction
st.subheader('Prediction')
st.markdown('''# $ {} '''.format(round(prediction), 2))

!streamlit run app.py
